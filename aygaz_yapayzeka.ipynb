{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsTVWSrxPHOpd9mh0N7Cxy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CenkAk/CenkAk/blob/master/aygaz_yapayzeka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7FvVPY75fAM"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install termcolor"
      ],
      "metadata": {
        "id": "MFCQ86CT5nsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "id": "ef5L-OeP6md4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-plot"
      ],
      "metadata": {
        "id": "5YuEc_fG6oy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "D3qpEyoQ6qkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "rZGa9eJV6rVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "laM04CsG6sLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "a7T4qPiP60uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets list"
      ],
      "metadata": {
        "id": "x5gmyyvU61n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/skin-cancer-mnist-ham10000.zip"
      ],
      "metadata": {
        "id": "Vw1QJWU162pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_skin = pd.read_csv('/content/HAM10000_metadata.csv')\n",
        "\n",
        "df_skin.head()"
      ],
      "metadata": {
        "id": "NT4cExd3656_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lesion names\n",
        "lesion_type_dict = {\n",
        "    'nv': 'Melanocytic nevi',\n",
        "    'mel': 'Melanoma',\n",
        "    'bkl': 'Benign keratosis-like lesions ',\n",
        "    'bcc': 'Basal cell carcinoma',\n",
        "    'akiec': 'Actinic keratoses',\n",
        "    'vasc': 'Vascular lesions',\n",
        "    'df': 'Dermatofibroma'\n",
        "}\n",
        "\n",
        "lesion_ID_dict = {\n",
        "    'nv': 0,\n",
        "    'mel': 1,\n",
        "    'bkl': 2,\n",
        "    'bcc': 3,\n",
        "    'akiec': 4,\n",
        "    'vasc': 5,\n",
        "    'df': 6\n",
        "}\n",
        "\n",
        "lesion_names = ['Melanocytic nevi','Melanoma','Benign keratosis-like lesions ',\n",
        "               'Basal cell carcinoma','Actinic keratoses','Vascular lesions',\n",
        "               'Dermatofibroma']\n",
        "\n",
        "lesion_names_short = ['nv','mel','bkl','bcc','akiec','vasc','df']\n",
        "\n",
        "df_skin['lesion_type']=df_skin['dx'].map(lesion_type_dict)\n",
        "df_skin['lesion_ID'] = df_skin['dx'].map(lesion_ID_dict)\n",
        "\n",
        "print('Total number of images',len(df_skin))\n",
        "print('The problem is unbalanced, since Melanocytic nevi is much more frequent that other labels')\n",
        "\n",
        "df_skin['lesion_type'].value_counts()"
      ],
      "metadata": {
        "id": "y6AWWFmP68cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the first image\n",
        "fname_images = np.array(df_skin['image_id'])\n",
        "file_to_read ='/content/HAM10000_images_part_1/'+str(fname_images[0])+'.jpg'\n",
        "\n",
        "import cv2\n",
        "from cv2 import imread, resize\n",
        "\n",
        "img = imread(file_to_read)\n",
        "img2 = resize(img,(100,100))\n",
        "\n",
        "# show one exampe image\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img[:,:,::-1])\n",
        "plt.title('Original image')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(img2[:,:,::-1])\n",
        "plt.title('Resized image for DenseNet')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P0mL3JXQ6_av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def produce_new_img(img2):\n",
        "    # produce new images by rotating of flipping the original one\n",
        "    # this helps to increase the dimension of the dataset, avoiding overfitting of a single class\n",
        "    imga = cv2.rotate(img2,cv2.ROTATE_90_CLOCKWISE)\n",
        "    imgb = cv2.rotate(img2,cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    imgc = cv2.rotate(img2,cv2.ROTATE_180)\n",
        "    imgd = cv2.flip(img2,0)\n",
        "    imge = cv2.flip(img2,1)\n",
        "    return imga,imgb,imgc,imgd,imge\n",
        "\n",
        "new_img = produce_new_img(img2)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(2,3,1)\n",
        "plt.imshow(img2[:,:,::-1])\n",
        "for i in range(5):\n",
        "    plt.subplot(2,3,2+i)\n",
        "    plt.imshow(new_img[i][:,:,::-1])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FysIjSod7A2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "lista1 = os.listdir('/content/HAM10000_images_part_1/')\n",
        "lista2 = os.listdir('/content/HAM10000_images_part_2/')\n",
        "\n",
        "\n",
        "#import images from folder 1\n",
        "for i in range(len(lista1)):\n",
        "    fname_image = lista1[i]\n",
        "    fname_ID = fname_image.replace('.jpg','')\n",
        "\n",
        "    #features\n",
        "    file_to_read ='/content/HAM10000_images_part_1/'+str(fname_image)\n",
        "    img = imread(file_to_read)\n",
        "    img2 = resize(img,(100,100))\n",
        "    X.append(img2)\n",
        "\n",
        "    #targets\n",
        "    output = np.array(df_skin[df_skin['image_id'] == fname_ID].lesion_ID)\n",
        "    y.append(output[0])\n",
        "\n",
        "    # add more images for class between 1-6, rotating them\n",
        "    if output != 0:\n",
        "        new_img = produce_new_img(img2)\n",
        "        for i in range(5):\n",
        "            X.append(new_img[i])\n",
        "            y.append(output[0])\n",
        "\n",
        "    if i % int(100) == 0:\n",
        "        print(i,'images loaded')\n",
        "\n",
        "# import images from folder 2\n",
        "for i in range(len(lista2)):\n",
        "    fname_image = lista2[i]\n",
        "    fname_ID = fname_image.replace('.jpg','')\n",
        "\n",
        "    #features\n",
        "    file_to_read ='/content/HAM10000_images_part_2/'+str(fname_image)\n",
        "    img = imread(file_to_read)\n",
        "    img2 = resize(img,(100,100))\n",
        "    X.append(img2)\n",
        "\n",
        "    #targets\n",
        "    output = np.array(df_skin[df_skin['image_id'] == fname_ID].lesion_ID)\n",
        "    y.append(output[0])\n",
        "\n",
        "    # add more images for class between 1-6\n",
        "    if output != 0:\n",
        "        new_img = produce_new_img(img2)\n",
        "        for i in range(5):\n",
        "            X.append(new_img[i])\n",
        "            y.append(output[0])\n",
        "\n",
        "    if i % int(100) == 0:\n",
        "\n",
        "        print(len(lista1)+i,'images loaded')"
      ],
      "metadata": {
        "id": "3cHhMDmp7Cmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install np_utils"
      ],
      "metadata": {
        "id": "dCySGy9z7DgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "y_train = to_categorical(y, num_classes=7)"
      ],
      "metadata": {
        "id": "U2Smb9S87EQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split in 80% training and 20% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_train, test_size=0.33, random_state=50,stratify=y)\n",
        "\n",
        "\n",
        "print('Train dataset shape',X_train.shape)\n",
        "print('Test dataset shape',X_test.shape)"
      ],
      "metadata": {
        "id": "76zXKF0O7GMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "IUtheDWi7HJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.layers import Dropout, Activation\n",
        "from keras.layers import Conv2D,BatchNormalization,MaxPool2D,Flatten,Dense"
      ],
      "metadata": {
        "id": "DFDIQ3tS7Hb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "y_id = np.array(df_skin['lesion_ID'])\n",
        "\n",
        "# compute weights for the loss function, because the problem is unbalanced\n",
        "class_weights = np.around(compute_class_weight(class_weight='balanced',classes=np.unique(y_id),y=y),2)\n",
        "class_weights = dict(zip(np.unique(y_id),class_weights))\n",
        "\n",
        "print('The problem is unbalanced. We need to provide class_weights ')\n",
        "print(class_weights)"
      ],
      "metadata": {
        "id": "Ur-4zevB7I5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building Neural Network\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Activation, Dropout, GlobalAveragePooling2D, \\\n",
        "    BatchNormalization, concatenate, AveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential([\n",
        "\n",
        "    # 1st convolutional layer\n",
        "    Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(100,100,3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "    # 2nd convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "    # 3rd convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 4th convolutional layer\n",
        "    Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    # 5th convolutional layer\n",
        "    Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    # 6th, Dense layer\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # 7th Dense layer\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # 8th output layer\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "jx8WYvY07Jo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(patience=100,monitor='val_accuracy')\n",
        "model_checkpoint_callback = ModelCheckpoint(filepath='model.h5',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='val_accuracy',\n",
        "                                            mode='auto',\n",
        "                                            save_best_only=True,\n",
        "                                            verbose=1)\n",
        "batch_size = 32\n",
        "epochs = 100\n",
        "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-3)\n",
        "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "datagen = ImageDataGenerator(zoom_range = 0.2, horizontal_flip=True, shear_range=0.2)\n",
        "\n",
        "datagen.fit(X_train)\n",
        "\n",
        "history=model.fit(datagen.flow(X_train,y_train), epochs=epochs, batch_size=batch_size, shuffle=True, callbacks=[early_stopping_monitor,model_checkpoint_callback], validation_data=(X_test, y_test), class_weight=class_weights)"
      ],
      "metadata": {
        "id": "MpFJkYu07KcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "metadata": {
        "id": "jbujQ80b7L0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DMf6UcBT7MU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "total = 0\n",
        "accurate = 0\n",
        "accurateindex = []\n",
        "wrongindex = []\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
        "        accurate += 1\n",
        "        accurateindex.append(i)\n",
        "    else:\n",
        "        wrongindex.append(i)\n",
        "\n",
        "    total += 1\n",
        "\n",
        "print('Total-test-data;', total, '\\taccurately-predicted-data:', accurate, '\\t wrongly-predicted-data: ', total - accurate)\n",
        "\n",
        "print('Accuracy:', round(accurate/total*100, 3), '%')"
      ],
      "metadata": {
        "id": "-779G2HE7NWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = load_model('model.h5')\n",
        "\n",
        "# compute predictions\n",
        "y_pred_prob = np.around(best_model.predict(X_test),3)\n",
        "y_pred = np.argmax(y_pred_prob,axis=1)\n",
        "\n",
        "y_test2 = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "cjsdYVE37N_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,16))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    index = i+100\n",
        "    plt.imshow(X_test[index,:,:,::-1])\n",
        "    label_exp = lesion_names[y_test2[index]]  #expected label\n",
        "    label_pred = lesion_names[y_pred[index]]  #predicted label\n",
        "    label_pred_prob = round(np.max(y_pred_prob[index])*100)\n",
        "    plt.title('Expected:'+str(label_exp)+'\\n Pred.:'+str(label_pred)+' ('+str(label_pred_prob)+'%)')\n",
        "plt.ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('final_figure.png',dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TuQg-8kR7OoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy for label equal to 0')\n",
        "print(np.mean(y_test2[y_test2 == 0] == y_pred[y_test2 == 0]))\n",
        "\n",
        "print('Accuracy for label different from 0')\n",
        "print(np.mean(y_test2[y_test2 != 0] == y_pred[y_test2 != 0]))"
      ],
      "metadata": {
        "id": "9kHVQhmy7PXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_tot= []\n",
        "\n",
        "for i in range(7):\n",
        "    acc_parz = round(np.mean(y_test2[y_test2 == i] == y_pred[y_test2 == i]),2)\n",
        "    lab_parz = lesion_names[i]\n",
        "    print('accuracy for',lab_parz,'=',acc_parz)\n",
        "    acc_tot.append(acc_parz)"
      ],
      "metadata": {
        "id": "ii9RkXwc7P7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_tot = np.array(acc_tot)\n",
        "freq = np.unique(y_test2,return_counts=True)[1]\n",
        "\n",
        "np.sum(acc_tot*freq)/np.sum(freq)"
      ],
      "metadata": {
        "id": "ipGaJmTk7QgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}